Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2018-06-18T17:24:38+05:30

====== kafka ======
Created Monday 18 June 2018

https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html

https://content.pivotal.io/blog/understanding-when-to-use-rabbitmq-or-apache-kafka

user: kafka
pass: times41!

installed on /opt/kafka
cd /opt/kafka/kafka_2.11-1.1.0/
run zookeper: ./bin/zookeeper-server-start.sh config/zookeeper.properties
./bin/kafka-server-start.sh config/server.properties

./bin/kafka-topics.sh --create   --zookeeper localhost:2181  --replication-factor 1 --partitions 13 --topic my-topic
./bin/kafka-topics.sh --list --zookeeper localhost:2181

./bin/kafka-console-producer.sh --broker-list localhost:9092   --topic my-topic

./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-topic --from-beginning



use kafka manager
cd  /opt/kafka-manager/target/universal/kafka-manager-1.3.3.17/
./bin/kafka-manager -Dkafka-manager.zkhosts="localhost:2181" -Dhttp.port=8181

use kafka kadmin
cd /opt/kafka-kadmin/kadmin/dist
java -jar shared-kafka-admin-micro-0.9.1.jar --spring.profiles.active=desired,Spring,profiles --server.port=9191

running zookeeper is required even fro single broker node cluster
kafka maintains order of message in same partition only, we can send message concerned message using partition key to same partition
kafka doesn't itself delete message, we can use retention policy/disk quota for auto removal OR
stop cluster and delete data for required partitionn from disk

As with a queue the consumer group allows you to divide up processing over a collection of processes (the members of the consumer group). As with publish-subscribe, Kafka allows you to broadcast messages to multiple consumer groups. the partitionâ€”within the topics, Kafka is able to provide both ordering guarantees and load balancing over a pool of consumer processes.
Note the key difference between Kafka Streams end-to-end exactly-once guarantee with other stream processing frameworks' claimed guarantees is that Kafka Streams tightly integrates with the underlying Kafka storage system and ensure that commits on the input topic offsets, updates on the state stores, and writes to the output topics will be completed atomically instead of treating Kafka as an external system that may have side-effects.

i guess distributed systems have atleast_once, exactly_once, atmost_once data gaurantees; timing or out of order guarantee problems.

running kafka using command line
http://cloudurable.com/blog/kafka-tutorial-kafka-from-command-line/index.html

kafka doesn't allow more than 1 consumer to read from same partition simultaneously
messages in topic are distributed among partitions
maintaining membership in the group is handled by the Kafka protocol dynamically. 
there is auto distribution of partition ownership among consumers 
zookeeper: required for comm among brokers
Kafka REST Proxy provides a RESTful interface to a Kafka cluster as kafka doesn't provide rest api on its own

kafka arch
https://thehoard.blog/how-kafkas-storage-internals-work-3a29b02e026
http://cloudurable.com/blog/kafka-architecture-low-level/index.html

kafka uses replication for in-sync replicas, which can be made master on failure. its not for read balanacing
we can dynamically change number of partitions, but kafka won't auto redistribute data

kafka-connect
https://docs.confluent.io/3.0.0/connect/userguide.html
kafka-connect producer and consumer properties:
http://kafka.apache.org/documentation.html#producerconfigs

kafka operations: adding nodes, partitions, reassignments:
https://svn.apache.org/repos/asf/kafka/site/082/ops.html

limiting kafka memory 
https://stackoverflow.com/questions/27681511/how-do-i-set-the-java-options-for-kafka

below fields are stored by kafka into zookeeper
https://cwiki.apache.org/confluence/display/KAFKA/Kafka+data+structures+in+Zookeeper

__quesitons__:
how number of partitions are decided, can they be cahnged later on
how many consumers should be run in cg
write and verify consumers in cgroup, what stragey is used toi determine number of consumers/cgs 
how is kafka stream scalable, how is transaction maintained in this system

__todo__
check some php lib

https://www.youtube.com/watch?v=CZ3wIuvmHeM




deleting topic directly from fs doesn't delete it













