Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2018-06-18T17:24:38+05:30

====== kafka ======
Created Monday 18 June 2018

https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html

https://content.pivotal.io/blog/understanding-when-to-use-rabbitmq-or-apache-kafka

user: kafka
pass: times41!

installed on /opt/kafka
cd /opt/kafka/kafka_2.11-1.1.0/
run zookeper: ./bin/zookeeper-server-start.sh config/zookeeper.properties
./bin/kafka-server-start.sh config/server.properties

./bin/kafka-topics.sh --create   --zookeeper localhost:2181  --replication-factor 1 --partitions 13 --topic my-topic
./bin/kafka-topics.sh --list --zookeeper [[localhost:2181]]

./bin/kafka-console-producer.sh --broker-list localhost:9092   --topic my-topic

./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-topic --from-beginning



use kafka manager
cd /opt/kafka-manager/target/universal/kafka-manager-1.3.3.17
./bin/kafka-manager -Dkafka-manager.zkhosts="localhost:2181"

running zookeeper is required even fro single broker node cluster
kafka maintains order of message in same partition only, we can send message concerned message using partition key to same partition
kafka doesn't itself delete message, we can use retention policy/disk quota for auto removal OR
stop cluster and delete data for required partitionn from disk

running kafka using command line
http://cloudurable.com/blog/kafka-tutorial-kafka-from-command-line/index.html

kafka doesn't allow more than 1 consumer to read from same partition simultaneously
messages in topic are distributed among partitions
maintaining membership in the group is handled by the Kafka protocol dynamically. 
there is auto distribution of partition ownership among consumers 
zookeeper: required for comm among brokers
Kafka REST Proxy provides a RESTful interface to a Kafka cluster as kafka doesn't provide rest api on its own

kafka arch
https://thehoard.blog/how-kafkas-storage-internals-work-3a29b02e026
http://cloudurable.com/blog/kafka-architecture-low-level/index.html

kafka uses replication for in-sync replicas, which can be made master on failure. its not for read balanacing
we can dynamically change number of partitions, but kafka won't auto redistribute data

kafka operations: adding nodes, partitions, reassignments:
https://svn.apache.org/repos/asf/kafka/site/082/ops.html

quesitons:
how number of partitions are decided, can they be cahnged later on
how many consumers should be run in cg

todo
check some php lib

https://www.youtube.com/watch?v=CZ3wIuvmHeM
